## Related Work

### Classical analysis and numerical treatment of damped oscillators  

The damped harmonic oscillator has been a staple example in textbooks on ordinary differential equations, mechanical vibrations, and control theory for many decades.  Classical references present the closed‑form solutions for the under‑damped, critically damped, and over‑damped regimes, and they use these formulas to illustrate concepts such as eigenvalue placement, modal decomposition, and energy dissipation.  From a numerical perspective, the same literature typically introduces the forward Euler method, the implicit backward Euler scheme, and the family of Runge–Kutta formulas as generic tools for integrating second‑order linear systems.  A recurring theme is the discussion of stiffness: when the damping ratio \(\zeta\) is large, the eigenvalues \(\lambda_{1,2}= -\zeta\omega_{0}\pm\omega_{0}\sqrt{\zeta^{2}-1}\) become widely separated in magnitude, and explicit methods require prohibitively small step sizes to remain stable.  Consequently, many authors advocate the use of implicit or semi‑implicit schemes for the over‑damped case, while retaining explicit high‑order methods for the under‑damped case.  The gap that remains in this body of work is a unified computational recipe that automatically adapts to the full range of \(\zeta\) without manual switching of solvers or hand‑tuned step sizes.  The present paper addresses this gap by demonstrating that a single adaptive Runge–Kutta implementation, when coupled with a robust error‑control strategy, can handle all regimes reliably.

### General‑purpose ODE solvers and adaptive Runge–Kutta methods  

Modern scientific computing environments provide sophisticated ODE integrators that encapsulate the adaptive step‑size logic described in the classical literature.  Standard references on numerical analysis of initial‑value problems detail the Dormand–Prince 5(4) pair, the Fehlberg 4(5) pair, and other embedded Runge–Kutta families that estimate local truncation error and adjust the step size on the fly.  Software libraries such as MATLAB’s `ode45`, Julia’s `DifferentialEquations.jl`, and Python’s SciPy `solve_ivp` expose these algorithms through a uniform API, allowing users to specify tolerances (`rtol`, `atol`) rather than explicit step sizes.  In practice, engineers often select a solver based on heuristics: `ode45` for non‑stiff problems, `ode15s` for stiff problems, and so on.  Recent surveys of ODE solver performance show that adaptive explicit Runge–Kutta methods can remain competitive even for mildly stiff linear systems when tolerances are chosen appropriately.  However, the literature rarely investigates the systematic performance of a single solver across the entire spectrum of damping ratios for a linear oscillator, nor does it provide a reproducible workflow that can be shared and rerun without modification.  This work builds directly on the capabilities of the Dormand–Prince method as implemented in SciPy, but it goes further by embedding the solver within a self‑contained simulation pipeline that is parameter‑agnostic, automatically selects tolerances based on the physical scales of the problem, and validates the output against the analytic expressions for each damping regime.

### Reproducible scientific computing ecosystems  

The last decade has seen a rapid expansion of open‑source scientific Python tools that emphasize reproducibility, version control, and environment management.  Standard references on reproducible research describe the use of virtual environments (e.g., `venv` or `conda`), dependency specification files (`requirements.txt` or `environment.yml`), and literate programming notebooks to capture both code and narrative.  In the context of dynamical‑system simulation, several community‑driven projects provide ready‑made templates for solving ODEs, visualizing phase‑space trajectories, and exporting results in portable formats.  While these resources demonstrate best practices for individual case studies, they seldom present a systematic benchmark that spans multiple dynamical regimes of a single model.  Moreover, most tutorials focus on the mechanics of plotting or on the syntax of the solver, leaving the question of how to guarantee that the same workflow yields accurate results for both stiff and non‑stiff parameter sets largely unanswered.  The current manuscript contributes to this strand of work by offering a complete, minimal Python package that includes: (i) a deterministic conversion of the second‑order equation to first‑order form, (ii) a single call to `solve_ivp` with adaptive error control, (iii) automated generation of reference analytic solutions for validation, and (iv) a set of reproducible scripts that can be executed on any platform supporting Python 3.11.  By packaging these elements together, the paper bridges the gap between generic reproducibility guidelines and the concrete needs of engineers who must simulate damped oscillators across a wide range of damping ratios.

### Benchmarking and validation practices for linear dynamical systems  

A separate line of research focuses on the establishment of benchmark problems for verifying ODE solvers.  Classic benchmark suites include the linear stiff test problem (the so‑called “van der Pol” in its linearized form) and the simple harmonic oscillator with added damping.  These suites are used to compare solver accuracy, stability regions, and computational cost.  The prevailing methodology is to compute a reference solution with a very small step size or with an analytical formula, and then to report error norms (e.g., \(L_{2}\) or maximum norm) for a range of tolerances.  While such studies provide valuable insight into solver behavior, they typically treat each damping regime in isolation and do not explore the continuity of solver performance as the damping ratio varies continuously from under‑damped to over‑damped.  The present work adopts the benchmarking philosophy but extends it by performing a parametric sweep over \(\zeta\) and by reporting a single error metric that captures the worst‑case deviation across all regimes.  This approach demonstrates that the same adaptive algorithm can meet a prescribed accuracy threshold without manual retuning, thereby confirming and extending the conclusions of earlier benchmark analyses.

### Positioning of the present study  

Taken together, the four thematic strands reveal a landscape in which (1) the analytical theory of damped oscillators is well understood, (2) adaptive Runge–Kutta solvers are mature and widely available, (3) reproducible scientific‑Python workflows are advocated but not yet specialized for multi‑regime oscillator simulation, and (4) benchmarking practices exist but rarely address a continuous transition across damping regimes.  The contribution of this paper is to synthesize these elements into a coherent, reproducible computational pipeline that fills the identified gaps: it confirms that a single Dormand–Prince implementation can handle both stiff and non‑stiff cases, it extends reproducibility guidelines by providing a ready‑to‑run example that spans the full \(\zeta\) spectrum, and it simplifies validation by automatically comparing numerical output to the closed‑form solutions for each regime.  In this way, the work complements classical textbooks, validates modern solver libraries, and enriches the suite of reproducible benchmarks available to the scientific and engineering communities.